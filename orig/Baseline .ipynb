{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tumor Image classification\n",
    "\n",
    "## Data Preparation\n",
    "\n",
    "Data Augmentation is performed on the given dataset. ImageDataGenerator function in Keras can used for preprocessing the data.\n",
    "\n",
    "The images in the given dataset didnt require any augmentation as the dataset had object of interest in focus. The data was imbalanced even after combining classes 0 , 1 into class 0 and classes 2 , 3 into class 1. Classes 1 was about half the size of class 0. Hence Class 1 was upsampled by using duplicatioon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 135 images belonging to 2 classes.\n",
      "Found 125 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255, \n",
    "shear_range = 0.2,\n",
    "zoom_range = 0.2,\n",
    "horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "training_set = train_datagen.flow_from_directory('E:\\\\NUS\\\\Interview dataset\\\\orig\\\\Train',\n",
    "target_size = (100, 100),\n",
    "batch_size = 32,\n",
    "classes = ['0','1'],                                                 \n",
    "class_mode = 'binary')\n",
    "test_set = test_datagen.flow_from_directory('E:\\\\NUS\\\\Interview dataset\\\\orig\\\\Test',\n",
    "target_size = (100, 100),\n",
    "batch_size = 32,\n",
    "class_mode = 'binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 100, 3)\n"
     ]
    }
   ],
   "source": [
    "print(test_set.image_shape)\n",
    "Y_test = test_set.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train = training_set.classes\n",
    "training_set.image_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model\n",
    "\n",
    "Simple CNN model with 2 layer convolutions with a filter size 3 * 3. The model runs for 25 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 98, 98, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 49, 49, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 47, 47, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 23, 23, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 16928)             0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               2166912   \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 2,177,185\n",
      "Trainable params: 2,177,185\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "# Initialising the CNN\n",
    "classifier = Sequential()\n",
    "# Step 1 - Convolution\n",
    "classifier.add(Conv2D(32, (3, 3), input_shape = (100, 100, 3), activation = 'relu')) \n",
    "# Step 2 - Pooling\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "# Adding a second convolutional layer\n",
    "classifier.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "# Step 3 - Flattening\n",
    "classifier.add(Flatten())\n",
    "# Step 4 - Full connection\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "# Compiling the CNN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "print(classifier.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "10/10 [==============================] - 56s 6s/step - loss: 0.6362 - acc: 0.6382 - val_loss: 0.5551 - val_acc: 0.7643\n",
      "Epoch 2/25\n",
      "10/10 [==============================] - 46s 5s/step - loss: 0.6052 - acc: 0.6618 - val_loss: 0.5117 - val_acc: 0.7878\n",
      "Epoch 3/25\n",
      "10/10 [==============================] - 40s 4s/step - loss: 0.5569 - acc: 0.7084 - val_loss: 0.5499 - val_acc: 0.7293\n",
      "Epoch 4/25\n",
      "10/10 [==============================] - 47s 5s/step - loss: 0.5789 - acc: 0.6921 - val_loss: 0.5278 - val_acc: 0.7685\n",
      "Epoch 5/25\n",
      "10/10 [==============================] - 43s 4s/step - loss: 0.5342 - acc: 0.7356 - val_loss: 0.4755 - val_acc: 0.8408\n",
      "Epoch 6/25\n",
      "10/10 [==============================] - 52s 5s/step - loss: 0.5649 - acc: 0.7406 - val_loss: 0.4944 - val_acc: 0.8457\n",
      "Epoch 7/25\n",
      "10/10 [==============================] - 48s 5s/step - loss: 0.5165 - acc: 0.7279 - val_loss: 0.4681 - val_acc: 0.8376\n",
      "Epoch 8/25\n",
      "10/10 [==============================] - 51s 5s/step - loss: 0.5652 - acc: 0.7000 - val_loss: 0.5339 - val_acc: 0.8199\n",
      "Epoch 9/25\n",
      "10/10 [==============================] - 63s 6s/step - loss: 0.5285 - acc: 0.7539 - val_loss: 0.4996 - val_acc: 0.7994\n",
      "Epoch 10/25\n",
      "10/10 [==============================] - 49s 5s/step - loss: 0.5267 - acc: 0.7440 - val_loss: 0.4612 - val_acc: 0.8521\n",
      "Epoch 11/25\n",
      "10/10 [==============================] - 41s 4s/step - loss: 0.5273 - acc: 0.7413 - val_loss: 0.5603 - val_acc: 0.7516\n",
      "Epoch 12/25\n",
      "10/10 [==============================] - 46s 5s/step - loss: 0.5316 - acc: 0.7194 - val_loss: 0.5032 - val_acc: 0.8328\n",
      "Epoch 13/25\n",
      "10/10 [==============================] - 47s 5s/step - loss: 0.5059 - acc: 0.7853 - val_loss: 0.4467 - val_acc: 0.8025\n",
      "Epoch 14/25\n",
      "10/10 [==============================] - 52s 5s/step - loss: 0.4415 - acc: 0.8000 - val_loss: 0.4709 - val_acc: 0.7974\n",
      "Epoch 15/25\n",
      "10/10 [==============================] - 46s 5s/step - loss: 0.5923 - acc: 0.6796 - val_loss: 0.5218 - val_acc: 0.8057\n",
      "Epoch 16/25\n",
      "10/10 [==============================] - 50s 5s/step - loss: 0.5563 - acc: 0.6326 - val_loss: 0.6322 - val_acc: 0.7492\n",
      "Epoch 17/25\n",
      "10/10 [==============================] - 53s 5s/step - loss: 0.5603 - acc: 0.7178 - val_loss: 0.5548 - val_acc: 0.8567\n",
      "Epoch 18/25\n",
      "10/10 [==============================] - 67s 7s/step - loss: 0.4986 - acc: 0.7717 - val_loss: 0.4952 - val_acc: 0.8232\n",
      "Epoch 19/25\n",
      "10/10 [==============================] - 50s 5s/step - loss: 0.4615 - acc: 0.7827 - val_loss: 0.4488 - val_acc: 0.8471\n",
      "Epoch 20/25\n",
      "10/10 [==============================] - 44s 4s/step - loss: 0.4324 - acc: 0.7821 - val_loss: 0.4292 - val_acc: 0.8489\n",
      "Epoch 21/25\n",
      "10/10 [==============================] - 45s 4s/step - loss: 0.4892 - acc: 0.7438 - val_loss: 0.5009 - val_acc: 0.8376\n",
      "Epoch 22/25\n",
      "10/10 [==============================] - 48s 5s/step - loss: 0.5090 - acc: 0.7279 - val_loss: 0.5363 - val_acc: 0.8457\n",
      "Epoch 23/25\n",
      "10/10 [==============================] - 45s 5s/step - loss: 0.4629 - acc: 0.8125 - val_loss: 0.4923 - val_acc: 0.8471\n",
      "Epoch 24/25\n",
      "10/10 [==============================] - 50s 5s/step - loss: 0.4561 - acc: 0.8052 - val_loss: 0.4758 - val_acc: 0.8232\n",
      "Epoch 25/25\n",
      "10/10 [==============================] - 53s 5s/step - loss: 0.4901 - acc: 0.7562 - val_loss: 0.4574 - val_acc: 0.8408\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17201232f60>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit_generator(training_set,\n",
    "steps_per_epoch = 10,\n",
    "epochs = 25,\n",
    "validation_data = test_set,\n",
    "validation_steps = 10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = training_set.classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "The model doesn't classify label 3 ie class 2 properly because the number of images is half of first class. Hence in the following model we have created a dataset with 2 times the existing images of label 3 (upsampling). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[55 25]\n",
      " [33 12]]\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.69      0.65        80\n",
      "          3       0.32      0.27      0.29        45\n",
      "\n",
      "avg / total       0.52      0.54      0.52       125\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Confution Matrix and Classification Report\n",
    "#https://gist.github.com/RyanAkilos/3808c17f79e77c4117de35aa68447045\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "Y_pred = classifier.predict_generator(test_set)\n",
    "y_pred = np.round(Y_pred)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(test_set.classes, y_pred))\n",
    "print('Classification Report')\n",
    "target_names = ['0', '1']\n",
    "print(classification_report(test_set.classes, y_pred, target_names=target_names))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Fine tuning parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 500 images belonging to 2 classes.\n",
      "Found 120 images belonging to 2 classes.\n",
      "Epoch 1/25\n",
      "50/50 [==============================] - 167s 3s/step - loss: 0.1693 - acc: 0.9266 - val_loss: 0.4673 - val_acc: 0.8418\n",
      "Epoch 2/25\n",
      "50/50 [==============================] - 149s 3s/step - loss: 0.1296 - acc: 0.9539 - val_loss: 0.5756 - val_acc: 0.8329\n",
      "Epoch 3/25\n",
      "50/50 [==============================] - 20647s 413s/step - loss: 0.1647 - acc: 0.9353 - val_loss: 0.4643 - val_acc: 0.8424\n",
      "Epoch 4/25\n",
      "50/50 [==============================] - 151s 3s/step - loss: 0.1367 - acc: 0.9384 - val_loss: 0.5370 - val_acc: 0.8242\n",
      "Epoch 5/25\n",
      "50/50 [==============================] - 150s 3s/step - loss: 0.1281 - acc: 0.9526 - val_loss: 0.4474 - val_acc: 0.8411\n",
      "Epoch 6/25\n",
      "50/50 [==============================] - 152s 3s/step - loss: 0.1107 - acc: 0.9620 - val_loss: 0.6536 - val_acc: 0.8001\n",
      "Epoch 7/25\n",
      "50/50 [==============================] - 152s 3s/step - loss: 0.1562 - acc: 0.9364 - val_loss: 0.5376 - val_acc: 0.8092\n",
      "Epoch 8/25\n",
      "50/50 [==============================] - 163s 3s/step - loss: 0.1090 - acc: 0.9565 - val_loss: 0.7038 - val_acc: 0.7988\n",
      "Epoch 9/25\n",
      "50/50 [==============================] - 144s 3s/step - loss: 0.1331 - acc: 0.9525 - val_loss: 0.5655 - val_acc: 0.8265\n",
      "Epoch 10/25\n",
      "50/50 [==============================] - 151s 3s/step - loss: 0.1112 - acc: 0.9573 - val_loss: 0.4270 - val_acc: 0.8997\n",
      "Epoch 11/25\n",
      "50/50 [==============================] - 155s 3s/step - loss: 0.0957 - acc: 0.9637 - val_loss: 0.6334 - val_acc: 0.8338\n",
      "Epoch 12/25\n",
      "50/50 [==============================] - 156s 3s/step - loss: 0.0851 - acc: 0.9643 - val_loss: 0.4758 - val_acc: 0.8663\n",
      "Epoch 13/25\n",
      "50/50 [==============================] - 155s 3s/step - loss: 0.0756 - acc: 0.9718 - val_loss: 0.5582 - val_acc: 0.8324\n",
      "Epoch 14/25\n",
      "50/50 [==============================] - 160s 3s/step - loss: 0.1209 - acc: 0.9550 - val_loss: 0.4950 - val_acc: 0.8757\n",
      "Epoch 15/25\n",
      "50/50 [==============================] - 167s 3s/step - loss: 0.0792 - acc: 0.9746 - val_loss: 0.5421 - val_acc: 0.8398\n",
      "Epoch 16/25\n",
      "50/50 [==============================] - 165s 3s/step - loss: 0.0646 - acc: 0.9745 - val_loss: 0.7038 - val_acc: 0.8349\n",
      "Epoch 17/25\n",
      "50/50 [==============================] - 153s 3s/step - loss: 0.0881 - acc: 0.9684 - val_loss: 0.6598 - val_acc: 0.8584\n",
      "Epoch 18/25\n",
      "50/50 [==============================] - 149s 3s/step - loss: 0.0655 - acc: 0.9738 - val_loss: 0.5308 - val_acc: 0.8155\n",
      "Epoch 19/25\n",
      "50/50 [==============================] - 154s 3s/step - loss: 0.0715 - acc: 0.9708 - val_loss: 0.5823 - val_acc: 0.8431\n",
      "Epoch 20/25\n",
      "50/50 [==============================] - 156s 3s/step - loss: 0.0636 - acc: 0.9784 - val_loss: 0.5961 - val_acc: 0.8316\n",
      "Epoch 21/25\n",
      "50/50 [==============================] - 155s 3s/step - loss: 0.0562 - acc: 0.9812 - val_loss: 0.6045 - val_acc: 0.8258\n",
      "Epoch 22/25\n",
      "50/50 [==============================] - 165s 3s/step - loss: 0.0819 - acc: 0.9713 - val_loss: 0.7464 - val_acc: 0.8416\n",
      "Epoch 23/25\n",
      "50/50 [==============================] - 160s 3s/step - loss: 0.0610 - acc: 0.9769 - val_loss: 0.5660 - val_acc: 0.8577\n",
      "Epoch 24/25\n",
      "50/50 [==============================] - 169s 3s/step - loss: 0.0430 - acc: 0.9844 - val_loss: 0.5836 - val_acc: 0.8503\n",
      "Epoch 25/25\n",
      "50/50 [==============================] - 149s 3s/step - loss: 0.0471 - acc: 0.9844 - val_loss: 0.7410 - val_acc: 0.8311\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x202316ac5c0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the CNN to the upsampled images for label 3\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "shear_range = 0.2,\n",
    "zoom_range = 0.2,\n",
    "horizontal_flip = True)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "training_set = train_datagen.flow_from_directory('E:\\\\NUS\\\\Interview dataset\\\\orig\\\\Train',\n",
    "target_size = (64, 64),\n",
    "batch_size = 32,\n",
    "class_mode = 'binary')\n",
    "test_set = test_datagen.flow_from_directory('E:\\\\NUS\\\\Interview dataset\\\\orig\\\\Test',\n",
    "target_size = (64, 64),\n",
    "batch_size = 32,\n",
    "class_mode = 'binary')\n",
    "classifier.fit_generator(training_set,\n",
    "steps_per_epoch = 50,\n",
    "epochs = 25,\n",
    "validation_data = test_set,\n",
    "validation_steps = 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[60  0]\n",
      " [60  0]]\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      1.00      0.67        60\n",
      "          3       0.00      0.00      0.00        60\n",
      "\n",
      "avg / total       0.25      0.50      0.33       120\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sownds\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#Confution Matrix and Classification Report\n",
    "#https://gist.github.com/RyanAkilos/3808c17f79e77c4117de35aa68447045\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "Y_pred = classifier.predict_generator(test_set, 120/ 33)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(test_set.classes, y_pred))\n",
    "print('Classification Report')\n",
    "target_names = ['0', '1']\n",
    "print(classification_report(test_set.classes, y_pred, target_names=target_names))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Deeper CNN \n",
    "\n",
    "A deeper model compared to previous simple CNN is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(100, 100, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(256, (5, 5)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# the model so far outputs 3D feature maps (height, width, features)\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='model_shapes.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "10/10 [==============================] - 58s 6s/step - loss: 1.6413 - acc: 0.5131 - val_loss: 0.7031 - val_acc: 0.3503\n",
      "Epoch 2/25\n",
      "10/10 [==============================] - 43s 4s/step - loss: 0.6971 - acc: 0.5015 - val_loss: 0.6467 - val_acc: 0.6945\n",
      "Epoch 3/25\n",
      "10/10 [==============================] - 43s 4s/step - loss: 0.7526 - acc: 0.4984 - val_loss: 0.6980 - val_acc: 0.3535\n",
      "Epoch 4/25\n",
      "10/10 [==============================] - 51s 5s/step - loss: 0.7152 - acc: 0.5105 - val_loss: 0.6353 - val_acc: 0.5723\n",
      "Epoch 5/25\n",
      "10/10 [==============================] - 42s 4s/step - loss: 0.7495 - acc: 0.5351 - val_loss: 0.6597 - val_acc: 0.6975\n",
      "Epoch 6/25\n",
      "10/10 [==============================] - 48s 5s/step - loss: 0.6941 - acc: 0.5215 - val_loss: 0.6502 - val_acc: 0.6688\n",
      "Epoch 7/25\n",
      "10/10 [==============================] - 47s 5s/step - loss: 0.7157 - acc: 0.5676 - val_loss: 0.6687 - val_acc: 0.7038\n",
      "Epoch 8/25\n",
      "10/10 [==============================] - 51s 5s/step - loss: 0.7681 - acc: 0.5451 - val_loss: 0.6514 - val_acc: 0.6881\n",
      "Epoch 9/25\n",
      "10/10 [==============================] - 52s 5s/step - loss: 0.6690 - acc: 0.6005 - val_loss: 0.5888 - val_acc: 0.7261\n",
      "Epoch 10/25\n",
      "10/10 [==============================] - 47s 5s/step - loss: 0.6960 - acc: 0.6483 - val_loss: 0.5857 - val_acc: 0.8103\n",
      "Epoch 11/25\n",
      "10/10 [==============================] - 40s 4s/step - loss: 0.6682 - acc: 0.6555 - val_loss: 0.5848 - val_acc: 0.7102\n",
      "Epoch 12/25\n",
      "10/10 [==============================] - 44s 4s/step - loss: 0.6863 - acc: 0.6763 - val_loss: 1.1161 - val_acc: 0.3730\n",
      "Epoch 13/25\n",
      "10/10 [==============================] - 38s 4s/step - loss: 0.6611 - acc: 0.6879 - val_loss: 0.5341 - val_acc: 0.7516\n",
      "Epoch 14/25\n",
      "10/10 [==============================] - 45s 4s/step - loss: 0.6171 - acc: 0.6719 - val_loss: 0.5975 - val_acc: 0.6913\n",
      "Epoch 15/25\n",
      "10/10 [==============================] - 41s 4s/step - loss: 0.6323 - acc: 0.6968 - val_loss: 0.5137 - val_acc: 0.8280\n",
      "Epoch 16/25\n",
      "10/10 [==============================] - 51s 5s/step - loss: 0.5766 - acc: 0.7242 - val_loss: 0.6386 - val_acc: 0.6399\n",
      "Epoch 17/25\n",
      "10/10 [==============================] - 48s 5s/step - loss: 0.6648 - acc: 0.7215 - val_loss: 0.4694 - val_acc: 0.8376\n",
      "Epoch 18/25\n",
      "10/10 [==============================] - 63s 6s/step - loss: 0.5584 - acc: 0.7089 - val_loss: 0.4763 - val_acc: 0.8553\n",
      "Epoch 19/25\n",
      "10/10 [==============================] - 45s 4s/step - loss: 0.6048 - acc: 0.7142 - val_loss: 0.6707 - val_acc: 0.3726\n",
      "Epoch 20/25\n",
      "10/10 [==============================] - 38s 4s/step - loss: 0.5398 - acc: 0.7126 - val_loss: 0.5992 - val_acc: 0.7042\n",
      "Epoch 21/25\n",
      "10/10 [==============================] - 36s 4s/step - loss: 0.5306 - acc: 0.7413 - val_loss: 0.4282 - val_acc: 0.8312\n",
      "Epoch 22/25\n",
      "10/10 [==============================] - 44s 4s/step - loss: 0.5322 - acc: 0.7281 - val_loss: 0.5095 - val_acc: 0.8489\n",
      "Epoch 23/25\n",
      "10/10 [==============================] - 44s 4s/step - loss: 0.5701 - acc: 0.7251 - val_loss: 0.4498 - val_acc: 0.8408\n",
      "Epoch 24/25\n",
      "10/10 [==============================] - 52s 5s/step - loss: 0.6042 - acc: 0.7206 - val_loss: 0.4803 - val_acc: 0.8457\n",
      "Epoch 25/25\n",
      "10/10 [==============================] - 56s 6s/step - loss: 0.5200 - acc: 0.7781 - val_loss: 0.4184 - val_acc: 0.8503\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17201253898>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(training_set,\n",
    "steps_per_epoch = 10,\n",
    "epochs = 25,\n",
    "validation_data = test_set,\n",
    "validation_steps = 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix\n",
    "\n",
    "Similar results to Model 1 were obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[57 23]\n",
      " [33 12]]\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.63      0.71      0.67        80\n",
      "          3       0.34      0.27      0.30        45\n",
      "\n",
      "avg / total       0.53      0.55      0.54       125\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Confution Matrix and Classification Report\n",
    "#https://gist.github.com/RyanAkilos/3808c17f79e77c4117de35aa68447045\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "Y_pred = model.predict_generator(test_set)\n",
    "y_pred = np.round(Y_pred)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(test_set.classes, y_pred))\n",
    "print('Classification Report')\n",
    "target_names = ['0', '3']\n",
    "print(classification_report(test_set.classes, y_pred, target_names=target_names))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
